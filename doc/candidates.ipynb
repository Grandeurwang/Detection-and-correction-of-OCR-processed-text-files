{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]               data  label\n",
      "0          proposal      1\n",
      "1                1n      0\n",
      "2           unclear      1\n",
      "3              been      1\n",
      "4          adequacy      1\n",
      "5                 7      0\n",
      "6               MCA      1\n",
      "7               the      1\n",
      "8               you      1\n",
      "9   recommendatlons      0\n",
      "10            thelr      1\n",
      "11              the      1\n",
      "12              Los      1\n",
      "13            afflx      1\n",
      "14    understandlng      0\n",
      "15             that      1\n",
      "16        posltlons      0\n",
      "17              the      1\n",
      "18         Drlnklng      0\n",
      "19       1ndustrlal      0\n",
      "[[12204  4508]\n",
      " [ 2622 24967]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77     16712\n",
      "           1       0.85      0.90      0.88     27589\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     44301\n",
      "   macro avg       0.84      0.82      0.82     44301\n",
      "weighted avg       0.84      0.84      0.84     44301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from detection import *\n",
    "\n",
    "words, label = labelTesseract()\n",
    "train_data, test_data, train_label, test_label = div_train(words, label)\n",
    "bigram_dict = compute_bigram()\n",
    "featureMatrix_train = buildFeatures(train_data, bigram_dict)\n",
    "featureMatrix_test = buildFeatures(test_data, bigram_dict)\n",
    "\n",
    "# uncomment for testing\n",
    "'''\n",
    "head = featureMatrix_train.head()\n",
    "print(head.to_string())\n",
    "'''\n",
    "\n",
    "# build classifier\n",
    "svm_class = SVC(kernel='rbf', verbose=True, gamma='scale')\n",
    "svm_class.fit(featureMatrix_train, train_label)\n",
    "\n",
    "# prediction\n",
    "prediction = svm_class.predict(featureMatrix_test)\n",
    "\n",
    "output = pd.DataFrame({'data': test_data,\n",
    "                       'label': prediction})\n",
    "\n",
    "print(output[:20])\n",
    "\n",
    "##### evaluation\n",
    "#confustion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_label, prediction))\n",
    "print(classification_report(test_label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = output[output.label == 0].reset_index(drop = True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all number\n",
    "cleaned_typos = []\n",
    "for typo in typos:\n",
    "    try:\n",
    "        int(typo)\n",
    "    except:\n",
    "        cleaned_typos.append(typo)\n",
    "cleaned_typos = pd.Series(cleaned_typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# remove puncutation and numbers\n",
    "cleaned_typos = cleaned_typos.str.replace(r\"[{}]\".format(string.punctuation + 'â€˜'),'')\n",
    "cleaned_typos = cleaned_typos.str.replace(r'\\d','')\n",
    "cleaned_typos = cleaned_typos[cleaned_typos != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_typos.to_csv('cleaned_typos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'CSW_corpus.txt'\n",
    "with open(fname) as file:\n",
    "    corpus = file.readlines()\n",
    "corpus = [x.strip() for x in corpus]   \n",
    "# delete first 2 rows\n",
    "corpus = corpus[2:]\n",
    "# de-capitalize\n",
    "corpus = [x.lower() for x in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from nltk import edit_distance\n",
    "\n",
    "def typo_classification(typo,correct):\n",
    "    if (len(typo) > len(correct)):\n",
    "        return 'insertion'\n",
    "    elif (len(typo) < len(correct)):\n",
    "        return 'deletion'\n",
    "    else:\n",
    "        typo_count = Counter(typo)\n",
    "        correct_count = Counter(correct)\n",
    "        if typo_count == correct_count:\n",
    "            return 'reversal'\n",
    "        else:\n",
    "            return 'subsititution'\n",
    "\n",
    "def find_candidates(typo,corpus):\n",
    "    candidates = []\n",
    "    candi_type = []\n",
    "    for word in corpus:\n",
    "        ed = edit_distance(typo,word)\n",
    "        word_type = typo_classification(typo,word)\n",
    "        if ((ed == 1) | ((ed == 2) & (word_type == 'reversal'))):\n",
    "            candidates.append(word)\n",
    "            candi_type.append(word_type)\n",
    "    return candidates,candi_type\n",
    "\n",
    "def find_position(typo,candidates):\n",
    "    position = []\n",
    "    for corr in candidates:\n",
    "        typo_type = typo_classification(typo,corr)\n",
    "        \n",
    "        if (typo_type == 'deletion'):\n",
    "            typo += '#'\n",
    "\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    if corr[i] != corr[i-1]:\n",
    "                        typo = typo[:-1]\n",
    "                        position.append([typo,corr,\"@\",corr[i],i,typo_type])\n",
    "                        break\n",
    "                    else:\n",
    "                        typo = typo[:-1]\n",
    "                        position.append([typo,corr,\"@\",corr[i],i,typo_type])\n",
    "                        position.append([typo,corr,\"@\",corr[i],i-1,typo_type])\n",
    "                        break\n",
    "                        \n",
    "                i += 1\n",
    "        elif (typo_type == 'insertion'):\n",
    "            corr += '#'\n",
    "\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    if typo[i] != typo[i-1]:\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"@\",i,typo_type])\n",
    "                        break\n",
    "                    elif ((typo[i] == typo[i-1])& (typo[i] == typo[i-2])):\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"@\",i,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"@\",i-1,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"@\",i-2,typo_type])\n",
    "                        break\n",
    "                    else:\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"@\",i,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"@\",i-1,typo_type])\n",
    "                        break\n",
    "                i += 1\n",
    "        elif (typo_type == 'subsititution'):\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    position.append([typo,corr,typo[i],corr[i],i,typo_type])\n",
    "                    break\n",
    "                i+=1\n",
    "                \n",
    "        elif (typo_type == 'reversal'):\n",
    "            i = 0\n",
    "            while i < len(corr)-1:\n",
    "                if ((typo[i] == corr[i+1]) & (typo[i+1] == corr[i])):\n",
    "                    typo_comb = typo[i] + typo[i+1]\n",
    "                    position.append([typo,corr,typo_comb,typo_comb[::-1],i,typo_type])\n",
    "                    break\n",
    "                i +=1\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput lowercase typo\n",
    "typo = 'ambitios'\n",
    "\n",
    "candidates,cand_type = find_candidates(typo,corpus)\n",
    "correction = find_position(typo,candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Correction</th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambitios</td>\n",
       "      <td>ambition</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>7</td>\n",
       "      <td>subsititution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambitios</td>\n",
       "      <td>ambitions</td>\n",
       "      <td>@</td>\n",
       "      <td>n</td>\n",
       "      <td>7</td>\n",
       "      <td>deletion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambitios</td>\n",
       "      <td>ambitious</td>\n",
       "      <td>@</td>\n",
       "      <td>u</td>\n",
       "      <td>7</td>\n",
       "      <td>deletion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Typo Correction old new  index           type\n",
       "0  ambitios   ambition   s   n      7  subsititution\n",
       "1  ambitios  ambitions   @   n      7       deletion\n",
       "2  ambitios  ambitious   @   u      7       deletion"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction = pd.DataFrame(correction)\n",
    "correction.columns = ['Typo','Correction','old','new','index','type']\n",
    "correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
