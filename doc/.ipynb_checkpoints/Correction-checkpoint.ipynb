{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from detection import *\n",
    "\n",
    "pair, words, label = labelTesseract()\n",
    "train_data, test_data, train_label, test_label, ground_truth_train, ground_truth_test = div_train(pair, label)\n",
    "\n",
    "# uncomment to test for truth, tesseract pair\n",
    "'''\n",
    "print(train_data[:10])\n",
    "print(ground_truth_train[:10])\n",
    "print(train_label[:10])\n",
    "\n",
    "print(test_data[:10])\n",
    "print(ground_truth_test[:10])\n",
    "print(test_label[:10])\n",
    "'''\n",
    "\n",
    "\n",
    "bigram_dict = compute_bigram()\n",
    "featureMatrix_train = buildFeatures(train_data, bigram_dict)\n",
    "featureMatrix_test = buildFeatures(test_data, bigram_dict)\n",
    "\n",
    "# uncomment for testing\n",
    "'''\n",
    "head = featureMatrix_train.head()\n",
    "print(head.to_string())\n",
    "'''\n",
    "\n",
    "# build classifier\n",
    "svm_class = SVC(kernel='rbf', verbose=True, gamma='scale')\n",
    "svm_class.fit(featureMatrix_train, train_label)\n",
    "\n",
    "# prediction\n",
    "prediction = svm_class.predict(featureMatrix_test)\n",
    "\n",
    "output = pd.DataFrame({'data': test_data,\n",
    "                       'label': prediction})\n",
    "\n",
    "print(output[:20])\n",
    "\n",
    "##### evaluation\n",
    "#confustion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_label, prediction))\n",
    "print(classification_report(test_label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = output[output.label == 0].reset_index(drop = True).data\n",
    "\n",
    "import string\n",
    "# remove puncutation and numbers\n",
    "cleaned_typos = cleaned_typos.str.extract(r'([a-zA-Z]+)').dropna()[0]\n",
    "cleaned_typos.reset_index(drop = True,inplace = True)\n",
    "cleaned_typos = cleaned_typos.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_typos.to_csv('cleaned_typos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "truth_counts = 0\n",
    "corpus = []\n",
    "# create a list of all .txt files\n",
    "truth_files_list = glob.glob('../data/ground_truth/*.txt')\n",
    "# reading the ground truth file\n",
    "for file in truth_files_list:\n",
    "    with open(file) as fd:\n",
    "        for line in fd:\n",
    "            each_line = line.strip().split()\n",
    "            for word in each_line:\n",
    "                corpus.append(word)\n",
    "                truth_counts += 1\n",
    "corpus = pd.Series(corpus)\n",
    "corpus = corpus.str.extract(r'([a-zA-Z]+)').dropna()[0]\n",
    "corpus = corpus.str.lower().unique()\n",
    "\n",
    "truth_clean = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_counts = 0\n",
    "teseract_clean = []\n",
    "# create a list of all .txt files\n",
    "truth_files_list = glob.glob('../data/tesseract/*.txt')\n",
    "# reading the ground truth file\n",
    "for file in truth_files_list:\n",
    "    with open(file) as fd:\n",
    "        for line in fd:\n",
    "            each_line = line.strip().split()\n",
    "            for word in each_line:\n",
    "                teseract_clean.append(word)\n",
    "                truth_counts += 1\n",
    "teseract_clean = pd.Series(teseract_clean)\n",
    "teseract_clean = teseract_clean.str.extract(r'([a-zA-Z]+)').dropna()[0]\n",
    "teseract_clean = teseract_clean.str.lower().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from nltk import edit_distance\n",
    "\n",
    "def typo_classification(typo,correct):\n",
    "    if (len(typo) > len(correct)):\n",
    "        return 'insertion'\n",
    "    elif (len(typo) < len(correct)):\n",
    "        return 'deletion'\n",
    "    else:\n",
    "        typo_count = Counter(typo)\n",
    "        correct_count = Counter(correct)\n",
    "        if typo_count == correct_count:\n",
    "            return 'reversal'\n",
    "        else:\n",
    "            return 'substitution'\n",
    "\n",
    "def find_candidates(typo,corpus):\n",
    "    candidates = []\n",
    "    candi_type = []\n",
    "    for word in corpus:\n",
    "        ed = edit_distance(typo,word)\n",
    "        word_type = typo_classification(typo,word)\n",
    "        if len(typo) > 5:\n",
    "            if ed in [1,2,3]:\n",
    "                candidates.append(word)\n",
    "                candi_type.append(word_type)\n",
    "        else:\n",
    "            if ((ed == 1) |((ed == 2) & (word_type == 'reversal'))):\n",
    "                candidates.append(word)\n",
    "                candi_type.append(word_type)\n",
    "    return candidates,candi_type\n",
    "\n",
    "def find_position(typo,candidates):\n",
    "    position = []\n",
    "    for corr in candidates:\n",
    "        typo_type = typo_classification(typo,corr)\n",
    "        \n",
    "        if (typo_type == 'deletion'):\n",
    "            typo += '#'\n",
    "\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    if corr[i] != corr[i-1]:\n",
    "                        typo = typo[:-1]\n",
    "                        position.append([typo,corr,\"#\",corr[i],i,typo_type])\n",
    "                        break\n",
    "                    else:\n",
    "                        typo = typo[:-1]\n",
    "                        position.append([typo,corr,\"#\",corr[i],i,typo_type])\n",
    "                        position.append([typo,corr,\"#\",corr[i],i-1,typo_type])\n",
    "                        break\n",
    "                        \n",
    "                i += 1\n",
    "        elif (typo_type == 'insertion'):\n",
    "            corr += '#'\n",
    "\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    if typo[i] != typo[i-1]:\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"#\",i,typo_type])\n",
    "                        break\n",
    "                    elif ((typo[i] == typo[i-1])& (typo[i] == typo[i-2])):\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"#\",i,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"#\",i-1,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"#\",i-2,typo_type])\n",
    "                        break\n",
    "                    else:\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"#\",i,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"#\",i-1,typo_type])\n",
    "                        break\n",
    "                i += 1\n",
    "        elif (typo_type == 'substitution'):\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    position.append([typo,corr,typo[i],corr[i],i,typo_type])\n",
    "                    break\n",
    "                i+=1\n",
    "                \n",
    "        elif (typo_type == 'reversal'):\n",
    "            i = 0\n",
    "            while i < len(corr)-1:\n",
    "                if ((typo[i] == corr[i+1]) & (typo[i+1] == corr[i])):\n",
    "                    typo_comb = typo[i] + typo[i+1]\n",
    "                    position.append([typo,corr,typo_comb,typo_comb[::-1],i,typo_type])\n",
    "                    break\n",
    "                i +=1\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionsub=pd.read_csv('../data/confusion_matrix/sub_matrix.csv',index_col = 0)\n",
    "confusionadd=pd.read_csv('../data/confusion_matrix/add_matrix.csv',index_col = 0)\n",
    "confusiondel=pd.read_csv('../data/confusion_matrix/del_matrix.csv',index_col = 0)\n",
    "confusionrev=pd.read_csv('../data/confusion_matrix/rev_matrix.csv',index_col = 0) \n",
    "corpus = set(truth_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = pd.DataFrame()\n",
    "\n",
    "def probabilityfunction(correction):\n",
    "    for i in range(0,correction.shape[0]):\n",
    "        typo = correction.iloc[i,0]\n",
    "        index=correction.iloc[i,4]\n",
    "        specificword=correction.iloc[i,1]\n",
    "        if correction.iloc[i,5]=='insertion':\n",
    "            if index != 0:\n",
    "\n",
    "                #index=correction.iloc[i,4]\n",
    "                X=specificword[index-1]\n",
    "                Y=typo[index]\n",
    "                add =confusionadd.loc[X,Y]\n",
    "                total=0\n",
    "                for z in range(0,len(truth_clean)):\n",
    "                    if X == '#':\n",
    "                        total += truth_clean[z].startswith(Y)\n",
    "                    else:\n",
    "                        total += truth_clean[z].count(X+Y)\n",
    "                    #lis.append(total)\n",
    "                correction.iloc[i,6]=add/total\n",
    "            if index == 0:\n",
    "                X='#'\n",
    "                Y=specificword[index]\n",
    "                add =confusionadd.loc[X,Y]\n",
    "                totall=len(truth_clean)\n",
    "\n",
    "                correction.iloc[i,6]=add/totall\n",
    "\n",
    "        if correction.iloc[i,5]=='deletion':\n",
    "            if index != 0:\n",
    "\n",
    "                #index=correction.iloc[i,4]\n",
    "                X=specificword[index-1]\n",
    "                Y=specificword[index]\n",
    "                delt=confusiondel.loc[X,Y]\n",
    "                total=0\n",
    "                for z in range(0,len(truth_clean)):\n",
    "                    total += truth_clean[z].count(X+Y)\n",
    "                    #lis.append(total)\n",
    "                correction.iloc[i,6]=delt/total\n",
    "\n",
    "\n",
    "            if index == 0:\n",
    "                X='#'\n",
    "                Y=specificword[index]\n",
    "                delt=confusiondel.loc[X,Y]\n",
    "                totall=len(truth_clean)\n",
    "\n",
    "                correction.iloc[i,6]=delt/totall\n",
    "        if correction.iloc[i,5]=='reversal':\n",
    "\n",
    "\n",
    "                #index=correction.iloc[i,4]\n",
    "                X=specificword[index]\n",
    "                Y=specificword[index+1]\n",
    "                rev=confusionrev.loc[X,Y]\n",
    "                total=0\n",
    "                for z in range(0,len(truth_clean)):\n",
    "                    total += truth_clean[z].count(X+Y)\n",
    "                    #lis.append(total)\n",
    "                correction.iloc[i,6]=rev/total\n",
    "\n",
    "\n",
    "        if correction.iloc[i,5]=='substitution':\n",
    "            X=correction.iloc[i,2]\n",
    "            Y=correction.iloc[i,3]\n",
    "            sub = confusionsub.loc[X,Y]\n",
    "            #lis.append(sub)\n",
    "\n",
    "            total=0\n",
    "            for z in range(0,len(truth_clean)):\n",
    "                \n",
    "                total += truth_clean[z].count(Y)\n",
    "                #lis.append(total)\n",
    "            correction.iloc[i,6]=sub/total\n",
    "        correction['probability of t given c'] = correction.iloc[i,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos =  pd.read_csv('cleaned_typos.csv') # Detection result(in list) \n",
    "typos = list(typos['n'])\n",
    "typos = [x.lower() for x in typos]\n",
    "wrong = pd.DataFrame(typos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac5f6d5f6af42078c2d0da7256ae667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12648), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "output = []\n",
    "no_correction = 0\n",
    "\n",
    "for typo in tqdm_notebook(typos):\n",
    "    try:\n",
    "        candidates,cand_type = find_candidates(typo,corpus)\n",
    "        correction = find_position(typo,candidates)\n",
    "        correction = pd.DataFrame(correction)\n",
    "\n",
    "        if correction.empty:  \n",
    "            output.append(typo)\n",
    "            no_correction += 1\n",
    "\n",
    "        else:\n",
    "            correction.columns = ['Typo','Correction','old','new','index','type']\n",
    "            correction = correction[correction['index'] >= 0]\n",
    "            \n",
    "            if len(correction) == 1:\n",
    "                output.append(correction.loc[0,'Correction'])\n",
    "            else:\n",
    "                # 1. calculate the prior\n",
    "\n",
    "                freq = [] # the number of times that the proposed correction c appears in the training set\n",
    "                for cor in correction['Correction']:\n",
    "                    freq.append(len(wrong[wrong[0] == cor]))    \n",
    "\n",
    "                N = len(truth_clean) +len(teseract_clean) # the number of words\n",
    "                vocabulary = truth_clean\n",
    "                V = len(set(vocabulary)) # the vocabulary size \n",
    "\n",
    "                prior = (pd.DataFrame(freq) + 0.5)/(N + V/2)\n",
    "\n",
    "                correction['probability of c'] = prior\n",
    "\n",
    "                # 2. Calculate the likelihood\n",
    "                correction['probability of t given c']='defalut value'\n",
    "                correction['probability of c']='defalut value'\n",
    "\n",
    "                probabilityfunction(correction)\n",
    "\n",
    "                # 3. Calculate the posterior and find the correction that has maximum posterior\n",
    "\n",
    "                correction['posterior'] = correction['probability of c'] * correction['probability of t given c']\n",
    "                p = correction[correction['posterior'] == max(correction['posterior'])]\n",
    "                maxp = p['Correction'][p['Correction'].index[0]]\n",
    "                output.append(''.join(maxp))\n",
    "    except:\n",
    "        print(typo)\n",
    "#         output.append(typo)\n",
    "#         no_correction += 1\n",
    "        break\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(output).to_csv('correction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Correction</th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taxwrtng</td>\n",
       "      <td>taxing</td>\n",
       "      <td>w</td>\n",
       "      <td>#</td>\n",
       "      <td>3</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Typo Correction old new  index       type\n",
       "0  taxwrtng     taxing   w   #      3  insertion"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typo = 'taxwrtng'\n",
    "candidates,cand_type = find_candidates(typo,corpus)\n",
    "correction = find_position(typo,candidates)\n",
    "correction = pd.DataFrame(correction)\n",
    "correction.columns = ['Typo','Correction','old','new','index','type']\n",
    "\n",
    "correction[correction['index'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "correction.columns = ['Typo','Correction','old','new','index','type']\n",
    "correction = correction[correction.index >= 0]\n",
    "\n",
    "# 1. calculate the prior\n",
    "\n",
    "freq = [] # the number of times that the proposed correction c appears in the training set\n",
    "for cor in correction['Correction']:\n",
    "    freq.append(len(wrong[wrong[0] == cor]))    \n",
    "\n",
    "N = len(truth_clean) +len(teseract_clean) # the number of words\n",
    "vocabulary = truth_clean\n",
    "V = len(set(vocabulary)) # the vocabulary size \n",
    "\n",
    "prior = (pd.DataFrame(freq) + 0.5)/(N + V/2)\n",
    "\n",
    "correction['probability of c'] = prior\n",
    "\n",
    "# 2. Calculate the likelihood\n",
    "correction['probability of t given c']='defalut value'\n",
    "correction['probability of c']='defalut value'\n",
    "\n",
    "probabilityfunction(correction)\n",
    "\n",
    "# 3. Calculate the posterior and find the correction that has maximum posterior\n",
    "\n",
    "# correction['posterior'] = correction['probability of c'] * correction['probability of t given c']\n",
    "# p = correction[correction['posterior'] == max(correction['posterior'])]\n",
    "# maxp = p['Correction'][p['Correction'].index[0]]\n",
    "# output.append(''.join(maxp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Correction</th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "      <th>probability of c</th>\n",
       "      <th>probability of t given c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taxwrtng</td>\n",
       "      <td>taxing</td>\n",
       "      <td>w</td>\n",
       "      <td>#</td>\n",
       "      <td>3</td>\n",
       "      <td>insertion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Typo Correction old new  index       type probability of c  \\\n",
       "0  taxwrtng     taxing   w   #      3  insertion              NaN   \n",
       "\n",
       "   probability of t given c  \n",
       "0                       NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X='taxing'[3-1]\n",
    "Y='taxwrtng'[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "add =confusionadd.loc[X,Y]\n",
    "total=0\n",
    "for z in range(0,len(truth_clean)):\n",
    "    if X == '#':\n",
    "        total += truth_clean[z].startswith(Y)\n",
    "    else:\n",
    "        total += truth_clean[z].count(X+Y)\n",
    "    #lis.append(total)\n",
    "# correction.iloc[i,6]=add/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionadd.loc['x','w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
