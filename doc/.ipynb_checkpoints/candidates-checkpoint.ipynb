{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]               data  label\n",
      "0          proposal      1\n",
      "1                1n      0\n",
      "2           unclear      1\n",
      "3              been      1\n",
      "4          adequacy      1\n",
      "5                 7      0\n",
      "6               MCA      1\n",
      "7               the      1\n",
      "8               you      1\n",
      "9   recommendatlons      0\n",
      "10            thelr      1\n",
      "11              the      1\n",
      "12              Los      1\n",
      "13            afflx      1\n",
      "14    understandlng      0\n",
      "15             that      1\n",
      "16        posltlons      0\n",
      "17              the      1\n",
      "18         Drlnklng      0\n",
      "19       1ndustrlal      0\n",
      "[[12204  4508]\n",
      " [ 2622 24967]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77     16712\n",
      "           1       0.85      0.90      0.88     27589\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     44301\n",
      "   macro avg       0.84      0.82      0.82     44301\n",
      "weighted avg       0.84      0.84      0.84     44301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from detection import *\n",
    "\n",
    "words, label = labelTesseract()\n",
    "train_data, test_data, train_label, test_label = div_train(words, label)\n",
    "bigram_dict = compute_bigram()\n",
    "featureMatrix_train = buildFeatures(train_data, bigram_dict)\n",
    "featureMatrix_test = buildFeatures(test_data, bigram_dict)\n",
    "\n",
    "# uncomment for testing\n",
    "'''\n",
    "head = featureMatrix_train.head()\n",
    "print(head.to_string())\n",
    "'''\n",
    "\n",
    "# build classifier\n",
    "svm_class = SVC(kernel='rbf', verbose=True, gamma='scale')\n",
    "svm_class.fit(featureMatrix_train, train_label)\n",
    "\n",
    "# prediction\n",
    "prediction = svm_class.predict(featureMatrix_test)\n",
    "\n",
    "output = pd.DataFrame({'data': test_data,\n",
    "                       'label': prediction})\n",
    "\n",
    "print(output[:20])\n",
    "\n",
    "##### evaluation\n",
    "#confustion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_label, prediction))\n",
    "print(classification_report(test_label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = output[output.label == 0].reset_index(drop = True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# remove puncutation and numbers\n",
    "cleaned_typos = cleaned_typos.str.extract(r'([a-zA-Z]+)').dropna()[0]\n",
    "cleaned_typos.reset_index(drop = True,inplace = True)\n",
    "cleaned_typos = cleaned_typos.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_typos.to_csv('cleaned_typos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "truth_counts = 0\n",
    "corpus = []\n",
    "# create a list of all .txt files\n",
    "truth_files_list = glob.glob('../data/ground_truth/*.txt')\n",
    "# reading the ground truth file\n",
    "for file in truth_files_list:\n",
    "    with open(file) as fd:\n",
    "        for line in fd:\n",
    "            each_line = line.strip().split()\n",
    "            for word in each_line:\n",
    "                corpus.append(word)\n",
    "                truth_counts += 1\n",
    "corpus = pd.Series(corpus)\n",
    "corpus = corpus.str.extract(r'([a-zA-Z]+)').dropna()[0]\n",
    "corpus = corpus.str.lower().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from nltk import edit_distance\n",
    "\n",
    "def typo_classification(typo,correct):\n",
    "    if (len(typo) > len(correct)):\n",
    "        return 'insertion'\n",
    "    elif (len(typo) < len(correct)):\n",
    "        return 'deletion'\n",
    "    else:\n",
    "        typo_count = Counter(typo)\n",
    "        correct_count = Counter(correct)\n",
    "        if typo_count == correct_count:\n",
    "            return 'reversal'\n",
    "        else:\n",
    "            return 'subsititution'\n",
    "\n",
    "def find_candidates(typo,corpus):\n",
    "    candidates = []\n",
    "    candi_type = []\n",
    "    \n",
    "    \n",
    "    for word in corpus:\n",
    "        ed = edit_distance(typo,word)\n",
    "        \n",
    "        word_type = typo_classification(typo,word)\n",
    "        if len(typo) > 8:\n",
    "            if ed in [1,2]:\n",
    "                candidates.append(word)\n",
    "                candi_type.append(word_type)\n",
    "        else:\n",
    "            if ((ed == 1) |((ed == 2) & (word_type == 'reversal'))):\n",
    "                candidates.append(word)\n",
    "                candi_type.append(word_type)\n",
    "    return candidates,candi_type\n",
    "\n",
    "def find_position(typo,candidates):\n",
    "    position = []\n",
    "    for corr in candidates:\n",
    "        typo_type = typo_classification(typo,corr)\n",
    "        \n",
    "        if (typo_type == 'deletion'):\n",
    "            typo += '#'\n",
    "\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    if corr[i] != corr[i-1]:\n",
    "                        typo = typo[:-1]\n",
    "                        position.append([typo,corr,\"@\",corr[i],i,typo_type])\n",
    "                        break\n",
    "                    else:\n",
    "                        typo = typo[:-1]\n",
    "                        position.append([typo,corr,\"@\",corr[i],i,typo_type])\n",
    "                        position.append([typo,corr,\"@\",corr[i],i+1,typo_type])\n",
    "                        break\n",
    "                        \n",
    "                i += 1\n",
    "        elif (typo_type == 'insertion'):\n",
    "            corr += '#'\n",
    "\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    if typo[i] != typo[i-1]:\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"@\",i,typo_type])\n",
    "                        break\n",
    "                    elif ((typo[i] == typo[i-1])& (typo[i] == typo[i-2])):\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"@\",i,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"@\",i-1,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"@\",i-2,typo_type])\n",
    "                        break\n",
    "                    else:\n",
    "                        corr = corr[:-1]\n",
    "                        position.append([typo,corr,typo[i],\"@\",i,typo_type])\n",
    "                        position.append([typo,corr,typo[i],\"@\",i-1,typo_type])\n",
    "                        break\n",
    "                i += 1\n",
    "        elif (typo_type == 'subsititution'):\n",
    "            i = 0\n",
    "            while i < len(corr):\n",
    "                if (corr[i] != typo[i]):\n",
    "                    position.append([typo,corr,typo[i],corr[i],i,typo_type])\n",
    "                    break\n",
    "                i+=1\n",
    "                \n",
    "        elif (typo_type == 'reversal'):\n",
    "            i = 0\n",
    "            while i < len(corr)-1:\n",
    "                if ((typo[i] == corr[i+1]) & (typo[i+1] == corr[i])):\n",
    "                    typo_comb = typo[i] + typo[i+1]\n",
    "                    position.append([typo,corr,typo_comb,typo_comb[::-1],i,typo_type])\n",
    "                    break\n",
    "                i +=1\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "september\n"
     ]
    }
   ],
   "source": [
    "# imput lowercase typo\n",
    "typo = cleaned_typos[123]\n",
    "print(typo)\n",
    "candidates,cand_type = find_candidates(typo,corpus)\n",
    "correction = find_position(typo,candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Correction</th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>september</td>\n",
       "      <td>stember</td>\n",
       "      <td>e</td>\n",
       "      <td>@</td>\n",
       "      <td>1</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>september</td>\n",
       "      <td>septemb</td>\n",
       "      <td>e</td>\n",
       "      <td>@</td>\n",
       "      <td>7</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>september</td>\n",
       "      <td>septembex</td>\n",
       "      <td>r</td>\n",
       "      <td>x</td>\n",
       "      <td>8</td>\n",
       "      <td>subsititution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Typo Correction old new  index           type\n",
       "0  september    stember   e   @      1      insertion\n",
       "1  september    septemb   e   @      7      insertion\n",
       "2  september  septembex   r   x      8  subsititution"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction = pd.DataFrame(correction)\n",
    "correction.columns = ['Typo','Correction','old','new','index','type']\n",
    "correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusiondel=pd.read_csv('C:/Users/Alienware/Desktop/ads project1/Spring2019-Proj4-grp6/data/confusion_matrix/add_matrix.csv')\n",
    "confusionsub=pd.read_csv('../data/confusion_matrix/sub_matrix.csv')\n",
    "confusionadd=pd.read_csv('../data/confusion_matrix/add_matrix.csv')\n",
    "confusiondel=pd.read_csv('../data/confusion_matrix/del_matrix.csv')\n",
    "confusionrev=pd.read_csv('../data/confusion_matrix/rev_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_counts = 0\n",
    "teseract_clean = []\n",
    "# create a list of all .txt files\n",
    "truth_files_list = glob.glob('../data/tesseract/*.txt')\n",
    "# reading the ground truth file\n",
    "for file in truth_files_list:\n",
    "    with open(file) as fd:\n",
    "        for line in fd:\n",
    "            each_line = line.strip().split()\n",
    "            for word in each_line:\n",
    "                teseract_clean.append(word)\n",
    "                truth_counts += 1\n",
    "teseract_clean = pd.Series(teseract_clean)\n",
    "teseract_clean = teseract_clean.str.extract(r'([a-zA-Z]+)').dropna()[0]\n",
    "teseract_clean = teseract_clean.str.lower().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['september', 'stember', 'e', '@', 1, 'insertion'],\n",
       "       ['september', 'septemb', 'e', '@', 7, 'insertion'],\n",
       "       ['september', 'septembex', 'r', 'x', 8, 'subsititution']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 insertion\n",
      "7 insertion\n",
      "8 subsititution\n"
     ]
    }
   ],
   "source": [
    "for row in correction.values:\n",
    "    typo = row[0]\n",
    "    specificword = row[1]\n",
    "    index = row[4]\n",
    "    typo_type = row[5]\n",
    "    \n",
    "    print(index,typo_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_t_given_c(correction_df):\n",
    "    correction_list = correction_df.values\n",
    "    \n",
    "    typo = row[0]\n",
    "    specificword = row[1]\n",
    "    index = row[4]\n",
    "    typo_type = row[5]\n",
    "    \n",
    "    if typo_type =='insertion':\n",
    "        if index != 0:\n",
    "            \n",
    "            #index=correction.iloc[i,4]\n",
    "            X=specificword[index-1]\n",
    "            Y=specificword[index]\n",
    "            haha=confusionadd[confusionadd.iloc[:,0]==X]\n",
    "            add=haha[Y].iloc[0]\n",
    "            total=0\n",
    "            for z in range(0,len(truth_clean)):\n",
    "                total=total+truth_clean[z].count(X+Y)\n",
    "                #lis.append(total)\n",
    "                result =add/total\n",
    "        if index == 0:\n",
    "            X='#'\n",
    "            Y=specificword[index]\n",
    "            haha=confusionadd[confusionadd.iloc[:,0]==X]\n",
    "            add=haha[Y].iloc[0]\n",
    "            totall=len(truth_clean)\n",
    "            \n",
    "            result =add/totall\n",
    "            \n",
    "    if correction.iloc[i,5]=='deletion':\n",
    "        if index != 0:\n",
    "            \n",
    "            #index=correction.iloc[i,4]\n",
    "            X=specificword[index-1]\n",
    "            Y=specificword[index]\n",
    "            haha=confusiondel[confusiondel.iloc[:,0]==X]\n",
    "            delt=haha[Y].iloc[0]\n",
    "            total=0\n",
    "            for z in range(0,len(truth_clean)):\n",
    "                total=total+truth_clean[z].count(X+Y)\n",
    "                #lis.append(total)\n",
    "                result =delt/total\n",
    "            \n",
    "            \n",
    "        if index == 0:\n",
    "            X='#'\n",
    "            Y=specificword[index]\n",
    "            haha=confusiondel[confusiondel.iloc[:,0]==X]\n",
    "            delt=haha[Y].iloc[0]\n",
    "            totall=len(truth_clean)\n",
    "            \n",
    "            result =delt/totall\n",
    "            \n",
    "    if correction.iloc[i,5]=='reversal':\n",
    "        \n",
    "            \n",
    "            #index=correction.iloc[i,4]\n",
    "            X=specificword[index]\n",
    "            Y=specificword[index+1]\n",
    "            haha=confusionrev[confusionrev.iloc[:,0]==X]\n",
    "            rev=haha[Y].iloc[0]\n",
    "            total=0\n",
    "            for z in range(0,len(truth_clean)):\n",
    "                total=total+truth_clean[z].count(X+Y)\n",
    "                #lis.append(total)\n",
    "                result =rev/total\n",
    "        \n",
    "                \n",
    "    if correction.iloc[i,5]=='substitution':\n",
    "        X=correction.iloc[i,2]\n",
    "        Y=correction.iloc[i,3]\n",
    "        heihei=confusionsub[confusionsub.iloc[:,0]==X]\n",
    "        sub=heihei[Y].iloc[0]\n",
    "        #lis.append(sub)\n",
    "\n",
    "        total=0\n",
    "        for z in range(0,len(truth_clean)):\n",
    "            total=total+truth_clean[z].count(Y)\n",
    "            #lis.append(total)\n",
    "            result =sub/total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(truth_clean)+len(teseract_clean)\n",
    "V=len(set(truth_clean))+len(set(teseract_clean))\n",
    "for a in range(0,correction.shape[0]):\n",
    "    cor=correction.iloc[a,1]\n",
    "    correction.iloc[a,7]=((truth_clean.tolist().count(cor)+teseract_clean.tolist().count(cor)) + 0.5)/(N + V/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>Correction</th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "      <th>probability of t given c</th>\n",
       "      <th>probability of c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>september</td>\n",
       "      <td>stember</td>\n",
       "      <td>e</td>\n",
       "      <td>@</td>\n",
       "      <td>1</td>\n",
       "      <td>insertion</td>\n",
       "      <td>0.05062</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>september</td>\n",
       "      <td>septemb</td>\n",
       "      <td>e</td>\n",
       "      <td>@</td>\n",
       "      <td>7</td>\n",
       "      <td>insertion</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>september</td>\n",
       "      <td>septembex</td>\n",
       "      <td>r</td>\n",
       "      <td>x</td>\n",
       "      <td>8</td>\n",
       "      <td>subsititution</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Typo Correction old new  index           type  \\\n",
       "0  september    stember   e   @      1      insertion   \n",
       "1  september    septemb   e   @      7      insertion   \n",
       "2  september  septembex   r   x      8  subsititution   \n",
       "\n",
       "   probability of t given c  probability of c  \n",
       "0                   0.05062          0.000047  \n",
       "1                   0.00000          0.000047  \n",
       "2                   0.00000          0.000047  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,correction.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_clean.tolist().count(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
